{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2b6b384",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8e32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf16cc",
   "metadata": {},
   "source": [
    "## Visualization setup and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Setup\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "def setup_figure(figsize=(10, 6)):\n",
    "    \"\"\"Set up a figure with the specified size\"\"\"\n",
    "    return plt.figure(figsize=figsize)\n",
    "\n",
    "def save_figure(filename, dpi=300, bbox_inches='tight'):\n",
    "    \"\"\"Save the current figure\"\"\"\n",
    "    plt.savefig(filename, dpi=dpi, bbox_inches=bbox_inches)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afec98cb",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "def load_data(file_path=\"Data set/Stock Prices Data Set.csv\"):\n",
    "    \"\"\"Load the stock price dataset and perform initial checks\"\"\"\n",
    "    try:\n",
    "        # Try to load the data\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded dataset with shape: {df.shape}\")\n",
    "        print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "        print(f\"\\nFirst 5 rows of the dataset:\")\n",
    "        print(df.head())\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the data: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c8111",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af57c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration\n",
    "def explore_data(df):\n",
    "    \"\"\"Perform comprehensive data exploration on the stock dataset\"\"\"\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    print(\"\\n=== Data Types ===\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\n=== DataFrame Information ===\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\n=== Descriptive Statistics ===\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\n=== Missing Values ===\")\n",
    "    missing = df.isnull().sum()\n",
    "    print(missing)\n",
    "    \n",
    "    # Check for duplicate rows\n",
    "    print(\"\\n=== Duplicate Rows ===\")\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"Number of duplicate rows: {duplicates}\")\n",
    "    \n",
    "    # Visualize stock price distributions\n",
    "    numeric_columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "    if all(col in df.columns for col in numeric_columns):\n",
    "        setup_figure(figsize=(14, 10))\n",
    "        for i, column in enumerate(numeric_columns):\n",
    "            plt.subplot(2, 3, i+1)\n",
    "            sns.histplot(df[column], bins=30, kde=True)\n",
    "            plt.title(f'Distribution of {column.capitalize()}')\n",
    "        plt.tight_layout()\n",
    "        save_figure(\"stock_price_distributions.png\")\n",
    "    \n",
    "    # Check distribution of stock symbols\n",
    "    if 'symbol' in df.columns:\n",
    "        print(\"\\n=== Stock Symbol Distribution ===\")\n",
    "        symbol_counts = df['symbol'].value_counts().head(10)\n",
    "        print(symbol_counts)\n",
    "        \n",
    "        # Plot symbol distribution (top 10)\n",
    "        setup_figure(figsize=(12, 6))\n",
    "        symbol_counts.plot(kind='bar', color='skyblue')\n",
    "        plt.title('Distribution of Top 10 Stock Symbols', fontsize=14)\n",
    "        plt.xlabel('Stock Symbol', fontsize=12)\n",
    "        plt.ylabel('Count', fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        save_figure(\"symbol_distribution.png\")\n",
    "    \n",
    "    # Create correlation matrix\n",
    "    corr_columns = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]\n",
    "    if len(corr_columns) > 1:\n",
    "        setup_figure(figsize=(10, 8))\n",
    "        correlation = df[corr_columns].corr()\n",
    "        mask = np.triu(correlation)\n",
    "        sns.heatmap(correlation, annot=True, fmt=\".2f\", cmap='coolwarm', mask=mask)\n",
    "        plt.title('Feature Correlation Heatmap', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        save_figure(\"correlation_heatmap.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3ebb0",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cafa4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess and clean the stock data for modeling\"\"\"\n",
    "    if df is None:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    print(\"\\n=== Data Preprocessing ===\")\n",
    "    \n",
    "    # Make a copy of the dataframe to avoid modifying the original\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Create a binary classification task: price increased or not\n",
    "    print(\"Creating binary target variable: price_increased\")\n",
    "    df_processed['price_increased'] = (df_processed['close'] > df_processed['open']).astype(int)\n",
    "    \n",
    "    # Check class distribution\n",
    "    print(f\"\\nClass distribution:\\n{df_processed['price_increased'].value_counts()}\")\n",
    "    print(f\"Class distribution (%):\\n{df_processed['price_increased'].value_counts(normalize=True) * 100}\")\n",
    "    \n",
    "    # Visualize class distribution\n",
    "    setup_figure(figsize=(8, 6))\n",
    "    ax = sns.countplot(x='price_increased', data=df_processed, palette=['salmon', 'lightgreen'])\n",
    "    plt.title('Distribution of Price Direction', fontsize=14)\n",
    "    plt.xlabel('Price Increased (1) vs. Not Increased (0)', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    \n",
    "    # Add count labels on top of bars\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height()}', \n",
    "                   (p.get_x() + p.get_width()/2., p.get_height()), \n",
    "                   ha='center', va='center', \n",
    "                   xytext=(0, 10), \n",
    "                   textcoords='offset points')\n",
    "    \n",
    "    save_figure(\"price_direction_distribution.png\")\n",
    "    \n",
    "    # Check for missing values and handle them\n",
    "    if df_processed.isnull().sum().sum() > 0:\n",
    "        print(\"Handling missing values...\")\n",
    "        # For numeric columns, fill with median\n",
    "        numeric_cols = df_processed.select_dtypes(include=['float64', 'int64']).columns\n",
    "        for col in numeric_cols:\n",
    "            if df_processed[col].isnull().sum() > 0:\n",
    "                df_processed[col].fillna(df_processed[col].median(), inplace=True)\n",
    "        \n",
    "        # For categorical columns, fill with mode\n",
    "        cat_cols = df_processed.select_dtypes(include=['object']).columns\n",
    "        for col in cat_cols:\n",
    "            if df_processed[col].isnull().sum() > 0:\n",
    "                df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)\n",
    "    \n",
    "    # Handle duplicates\n",
    "    if df_processed.duplicated().sum() > 0:\n",
    "        print(f\"Removing {df_processed.duplicated().sum()} duplicate rows...\")\n",
    "        df_processed = df_processed.drop_duplicates()\n",
    "    \n",
    "    # Split features and target\n",
    "    y = df_processed['price_increased']\n",
    "    \n",
    "    # Define features to be used initially\n",
    "    # We'll drop the target, date, symbol, and the raw price columns that would cause data leakage\n",
    "    drop_columns = ['price_increased', 'open', 'high', 'low', 'close', 'adjusted_close', 'date', 'symbol']\n",
    "    X = df_processed.drop(columns=[col for col in drop_columns if col in df_processed.columns])\n",
    "    \n",
    "    print(f\"Feature matrix shape after initial selection: {X.shape}\")\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set shape: {X_train.shape}, Test set shape: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3922370",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8daf173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def engineer_features(df):\n",
    "    \"\"\"Perform feature engineering on the stock dataset\"\"\"\n",
    "    print(\"\\n=== Feature Engineering ===\")\n",
    "    \n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_eng = df.copy()\n",
    "    \n",
    "    # 1. Calculate daily price change percentage\n",
    "    if all(col in df_eng.columns for col in ['close', 'open']):\n",
    "        print(\"Creating price change percentage feature...\")\n",
    "        df_eng['price_change_pct'] = ((df_eng['close'] - df_eng['open']) / df_eng['open']) * 100\n",
    "    \n",
    "    # 2. Calculate high-low range as percentage of opening price\n",
    "    if all(col in df_eng.columns for col in ['high', 'low', 'open']):\n",
    "        print(\"Creating high-low range percentage feature...\")\n",
    "        df_eng['hl_range_pct'] = ((df_eng['high'] - df_eng['low']) / df_eng['open']) * 100\n",
    "    \n",
    "    # 3. Calculate volume relative to the stock's average volume\n",
    "    if all(col in df_eng.columns for col in ['volume', 'symbol']):\n",
    "        print(\"Creating relative volume feature...\")\n",
    "        # First, group by symbol to get each stock's average volume\n",
    "        avg_volumes = df_eng.groupby('symbol')['volume'].mean()\n",
    "        df_eng['rel_volume'] = df_eng.apply(lambda row: row['volume'] / avg_volumes[row['symbol']], axis=1)\n",
    "    \n",
    "    # 4. Calculate moving averages (if date information is available)\n",
    "    if 'date' in df_eng.columns:\n",
    "        try:\n",
    "            # Convert date to datetime if it's not already\n",
    "            if df_eng['date'].dtype == 'object':\n",
    "                df_eng['date'] = pd.to_datetime(df_eng['date'])\n",
    "            \n",
    "            # Sort by symbol and date\n",
    "            df_eng = df_eng.sort_values(['symbol', 'date'])\n",
    "            \n",
    "            # Group by symbol and calculate moving averages\n",
    "            print(\"Creating moving average features...\")\n",
    "            for symbol in df_eng['symbol'].unique():\n",
    "                mask = df_eng['symbol'] == symbol\n",
    "                # 5-day moving average of closing price\n",
    "                df_eng.loc[mask, 'ma5_close'] = df_eng.loc[mask, 'close'].rolling(window=5).mean()\n",
    "                # 10-day moving average of closing price\n",
    "                df_eng.loc[mask, 'ma10_close'] = df_eng.loc[mask, 'close'].rolling(window=10).mean()\n",
    "                # 5-day moving average of volume\n",
    "                df_eng.loc[mask, 'ma5_volume'] = df_eng.loc[mask, 'volume'].rolling(window=5).mean()\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating moving averages: {e}\")\n",
    "    \n",
    "    # 5. Calculate price volatility (rolling standard deviation)\n",
    "    if 'date' in df_eng.columns and 'close' in df_eng.columns:\n",
    "        try:\n",
    "            print(\"Creating volatility features...\")\n",
    "            for symbol in df_eng['symbol'].unique():\n",
    "                mask = df_eng['symbol'] == symbol\n",
    "                # 5-day volatility\n",
    "                df_eng.loc[mask, 'volatility_5d'] = df_eng.loc[mask, 'close'].rolling(window=5).std()\n",
    "                # 10-day volatility\n",
    "                df_eng.loc[mask, 'volatility_10d'] = df_eng.loc[mask, 'close'].rolling(window=10).std()\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating volatility features: {e}\")\n",
    "    \n",
    "    # 6. Create normalized features (normalize each numeric feature by its mean)\n",
    "    print(\"Creating normalized features...\")\n",
    "    numeric_cols = df_eng.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['price_increased']:  # Don't normalize the target\n",
    "            mean_val = df_eng[col].mean()\n",
    "            df_eng[f'norm_{col}'] = df_eng[col] / mean_val\n",
    "    \n",
    "    # Drop rows with missing values after feature engineering\n",
    "    missing_count = df_eng.isnull().sum().sum()\n",
    "    if missing_count > 0:\n",
    "        print(f\"Dropping {missing_count} rows with missing values after feature engineering...\")\n",
    "        df_eng = df_eng.dropna()\n",
    "    \n",
    "    print(f\"Original feature count: {df.shape[1]}\")\n",
    "    print(f\"Engineered feature count: {df_eng.shape[1]}\")\n",
    "    \n",
    "    # Print new features\n",
    "    new_features = set(df_eng.columns) - set(df.columns)\n",
    "    print(f\"New features created: {new_features}\")\n",
    "    \n",
    "    return df_eng\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22015acf",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8def0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "def select_features(X_train, X_test, y_train, k=None):\n",
    "    \"\"\"Select the most important features using SelectKBest\"\"\"\n",
    "    print(\"\\n=== Feature Selection ===\")\n",
    "    \n",
    "    # If k is not specified, use half of the features or 10, whichever is smaller\n",
    "    if k is None:\n",
    "        k = min(10, X_train.shape[1] // 2)\n",
    "    \n",
    "    # Select top k features\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    selected_features = X_train.columns[selected_indices]\n",
    "    print(f\"Selected {k} features: {selected_features.tolist()}\")\n",
    "    \n",
    "    # Create dataframes with selected features\n",
    "    X_train_selected_df = pd.DataFrame(X_train_selected, columns=selected_features)\n",
    "    X_test_selected_df = pd.DataFrame(X_test_selected, columns=selected_features)\n",
    "    \n",
    "    # Plot feature importance scores\n",
    "    setup_figure(figsize=(12, 6))\n",
    "    feature_scores = pd.Series(selector.scores_, index=X_train.columns)\n",
    "    feature_scores = feature_scores.sort_values(ascending=False)\n",
    "    sns.barplot(x=feature_scores.values, y=feature_scores.index)\n",
    "    plt.title('Feature Importance Scores (ANOVA F-value)', fontsize=14)\n",
    "    plt.xlabel('F-value', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    save_figure(\"feature_importance_scores.png\")\n",
    "    \n",
    "    return X_train_selected_df, X_test_selected_df, selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d956aa",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Using 3 models, SVM(Linear kernel), SVM(RBF kernel), SVM(Polynomial kernel). Uncomment the polynomial kernel if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a19c66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "def train_svm_models(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Train different SVM models and return the results\"\"\"\n",
    "    print(\"\\n=== Training SVM Models ===\")\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Define models with different kernels\n",
    "    models = {\n",
    "        'SVM (Linear Kernel)': SVC(kernel='linear', C=1.0, random_state=42, probability=True),\n",
    "        'SVM (RBF Kernel)': SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, probability=True),\n",
    "        # 'SVM (Polynomial Kernel)': SVC(kernel='poly', degree=3, C=1.0, random_state=42, probability=True)\n",
    "    }\n",
    "    \n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        try:\n",
    "            auc_score = roc_auc_score(y_test, y_prob)\n",
    "        except:\n",
    "            auc_score = 0.5  # Default value if AUC calculation fails\n",
    "        \n",
    "        print(f\"Performance of {name}:\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n",
    "        print(f\"  AUC: {auc_score:.4f}\")\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'scaler': scaler,\n",
    "            'y_pred': y_pred,\n",
    "            'y_prob': y_prob,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'auc': auc_score\n",
    "        }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a12efc",
   "metadata": {},
   "source": [
    "## Model Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e1ff95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Optimization\n",
    "def optimize_svm_hyperparameters(X_train, y_train, kernel='rbf'):\n",
    "    \"\"\"Find optimal hyperparameters for SVM using grid search\"\"\"\n",
    "    print(f\"\\n=== Optimizing SVM Hyperparameters for {kernel} kernel ===\")\n",
    "    \n",
    "    # Define the pipeline with scaling\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(kernel=kernel, probability=True, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Define parameter grid based on kernel\n",
    "    if kernel == 'linear':\n",
    "        param_grid = {\n",
    "            'svm__C': [0.1, 1, 10, 100]\n",
    "        }\n",
    "    elif kernel == 'rbf':\n",
    "        param_grid = {\n",
    "            'svm__C': [0.1, 1, 10, 100],\n",
    "            'svm__gamma': ['scale', 'auto', 0.1, 0.01]\n",
    "        }\n",
    "    elif kernel == 'poly':\n",
    "        param_grid = {\n",
    "            'svm__C': [0.1, 1, 10],\n",
    "            'svm__degree': [2, 3, 4],\n",
    "            'svm__gamma': ['scale', 'auto', 0.1]\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Unsupported kernel: {kernel}\")\n",
    "        return None\n",
    "    \n",
    "    # Create and run grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=2, scoring='accuracy', verbose=1, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Get the best estimator\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Store CV results in a DataFrame for visualization\n",
    "    cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "    \n",
    "    # Plot CV results\n",
    "    if kernel == 'linear':\n",
    "        setup_figure(figsize=(10, 6))\n",
    "        plt.plot(cv_results['param_svm__C'], cv_results['mean_test_score'], marker='o')\n",
    "        plt.xscale('log')\n",
    "        plt.title(f'Grid Search Results for {kernel} SVM', fontsize=14)\n",
    "        plt.xlabel('C parameter', fontsize=12)\n",
    "        plt.ylabel('Mean CV Accuracy', fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        save_figure(f\"grid_search_{kernel}_svm.png\")\n",
    "    elif kernel == 'rbf':\n",
    "        setup_figure(figsize=(12, 8))\n",
    "        # Group by gamma\n",
    "        gamma_values = cv_results['param_svm__gamma'].unique()\n",
    "        for gamma in gamma_values:\n",
    "            subset = cv_results[cv_results['param_svm__gamma'] == gamma]\n",
    "            plt.plot(subset['param_svm__C'], subset['mean_test_score'], \n",
    "                     marker='o', label=f'gamma = {gamma}')\n",
    "        plt.xscale('log')\n",
    "        plt.title(f'Grid Search Results for {kernel} SVM', fontsize=14)\n",
    "        plt.xlabel('C parameter', fontsize=12)\n",
    "        plt.ylabel('Mean CV Accuracy', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        save_figure(f\"grid_search_{kernel}_svm.png\")\n",
    "    \n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf86a19",
   "metadata": {},
   "source": [
    "## Cross-Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6a59808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "def perform_cross_validation(X, y, model):\n",
    "    \"\"\"Perform cross-validation to evaluate model performance\"\"\"\n",
    "    print(\"\\n=== Cross-Validation Evaluation ===\")\n",
    "    \n",
    "    # Define the pipeline with scaling\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Perform 2-fold cross-validation\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=2, scoring='accuracy')\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Cross-validation accuracy scores: {cv_scores}\")\n",
    "    print(f\"Mean CV accuracy: {cv_scores.mean():.4f}\")\n",
    "    print(f\"Standard deviation of CV accuracy: {cv_scores.std():.4f}\")\n",
    "    \n",
    "    return cv_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e3f94",
   "metadata": {},
   "source": [
    "## Evaluate Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3670991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models\n",
    "def evaluate_model(model_results, X_test, y_test, model_name):\n",
    "    \"\"\"Evaluate model performance using various metrics\"\"\"\n",
    "    print(f\"\\n=== Evaluating {model_name} ===\")\n",
    "    \n",
    "    # Extract model and predictions\n",
    "    y_pred = model_results['y_pred']\n",
    "    y_prob = model_results['y_prob']\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = model_results['accuracy']\n",
    "    precision = model_results['precision']\n",
    "    recall = model_results['recall']\n",
    "    f1 = model_results['f1']\n",
    "    auc_score = model_results['auc']\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC: {auc_score:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Price Decreased/Same', 'Price Increased']))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    setup_figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Price Decreased/Same', 'Price Increased'],\n",
    "                yticklabels=['Price Decreased/Same', 'Price Increased'])\n",
    "    plt.xlabel('Predicted', fontsize=12)\n",
    "    plt.ylabel('Actual', fontsize=12)\n",
    "    plt.title(f'Confusion Matrix - {model_name}', fontsize=14)\n",
    "    save_figure(f\"confusion_matrix_{model_name.lower().replace(' ', '_')}.png\")\n",
    "    \n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    setup_figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title(f'ROC Curve - {model_name}', fontsize=14)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    save_figure(f\"roc_curve_{model_name.lower().replace(' ', '_')}.png\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d565437",
   "metadata": {},
   "source": [
    "## # Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b296f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Models\n",
    "def compare_models(results):\n",
    "    \"\"\"Compare the performance of different SVM models\"\"\"\n",
    "    print(\"\\n=== Model Comparison ===\")\n",
    "    \n",
    "    # Create a comparison table\n",
    "    comparison_data = {\n",
    "        name: {\n",
    "            'Accuracy': results[name]['accuracy'],\n",
    "            'Precision': results[name]['precision'],\n",
    "            'Recall': results[name]['recall'],\n",
    "            'F1 Score': results[name]['f1'],\n",
    "            'AUC': results[name]['auc']\n",
    "        }\n",
    "        for name in results.keys()\n",
    "    }\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Print the comparison table\n",
    "    print(comparison_df)\n",
    "    \n",
    "    # Plot comparison\n",
    "    setup_figure(figsize=(12, 8))\n",
    "    comparison_df.plot(kind='bar', figsize=(12, 8))\n",
    "    plt.title('SVM Model Performance Comparison', fontsize=14)\n",
    "    plt.ylabel('Score', fontsize=12)\n",
    "    plt.xlabel('Metric', fontsize=12)\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.legend(title='Model')\n",
    "    plt.tight_layout()\n",
    "    save_figure(\"model_comparison.png\")\n",
    "    \n",
    "    # Find the best model based on accuracy\n",
    "    best_model_name = max(results.keys(), key=lambda k: results[k]['accuracy'])\n",
    "    print(f\"\\nBest model based on accuracy: {best_model_name}\")\n",
    "    print(f\"Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n",
    "    \n",
    "    return best_model_name, results[best_model_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca092b8",
   "metadata": {},
   "source": [
    "## Model Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b3f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Visualization\n",
    "def visualize_decision_boundary(model_results, X_test, y_test, feature_names, title):\n",
    "    \"\"\"Visualize decision boundary for SVM model\"\"\"\n",
    "    print(f\"\\n=== Visualizing Decision Boundary for {title} ===\")\n",
    "    \n",
    "    # Extract model and scaler\n",
    "    model = model_results['model']\n",
    "    scaler = model_results['scaler']\n",
    "    \n",
    "    # We can only visualize 2D decision boundaries\n",
    "    # Let's select the two most important features\n",
    "    if len(feature_names) > 2:\n",
    "        print(\"Selecting the first two features for visualization...\")\n",
    "        feature_indices = [0, 1]\n",
    "        feature_names_selected = feature_names[:2]\n",
    "    else:\n",
    "        feature_indices = range(len(feature_names))\n",
    "        feature_names_selected = feature_names\n",
    "    \n",
    "    # Extract the selected features\n",
    "    X_visual = X_test.iloc[:, feature_indices].values\n",
    "    \n",
    "    # Scale the features\n",
    "    X_visual_scaled = scaler.transform(X_test)[:, feature_indices]\n",
    "    \n",
    "    # Create a mesh grid\n",
    "    h = 0.02  # step size in the mesh\n",
    "    x_min, x_max = X_visual_scaled[:, 0].min() - 1, X_visual_scaled[:, 0].max() + 1\n",
    "    y_min, y_max = X_visual_scaled[:, 1].min() - 1, X_visual_scaled[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Create full feature vector with zeros for non-visualized features\n",
    "    if model.n_features_in_ > 2:\n",
    "        mesh_points = np.zeros((xx.ravel().shape[0], model.n_features_in_))\n",
    "        mesh_points[:, feature_indices] = np.c_[xx.ravel(), yy.ravel()]\n",
    "    else:\n",
    "        mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    # Predict labels for mesh grid points\n",
    "    Z = model.predict(mesh_points)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot the decision boundary and training points\n",
    "    setup_figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdBu)\n",
    "    \n",
    "    # Plot the training points\n",
    "    scatter = plt.scatter(X_visual_scaled[:, 0], X_visual_scaled[:, 1], \n",
    "                c=y_test, edgecolors='k', cmap=plt.cm.RdBu)\n",
    "    \n",
    "    plt.xlabel(feature_names_selected[0], fontsize=12)\n",
    "    plt.ylabel(feature_names_selected[1], fontsize=12)\n",
    "    plt.title(f'Decision Boundary - {title}', fontsize=14)\n",
    "    plt.legend(*scatter.legend_elements(), title='Price Direction')\n",
    "    plt.tight_layout()\n",
    "    save_figure(f\"decision_boundary_{title.lower().replace(' ', '_')}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3516989a",
   "metadata": {},
   "source": [
    "## Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28f5a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "def save_model(model, scaler, selected_features, filename='svm_stock_model.pkl'):\n",
    "    \"\"\"Save the trained model to a file\"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    # Create a dictionary with all components needed for prediction\n",
    "    model_package = {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'selected_features': selected_features\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    try:\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(model_package, f)\n",
    "        print(f\"\\nModel successfully saved to {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e4a9bd",
   "metadata": {},
   "source": [
    "## Main Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc3b7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVM Classification for Stock Price Direction Prediction ===\n",
      "Successfully loaded dataset with shape: (497472, 7)\n",
      "\n",
      "Columns: ['symbol', 'date', 'open', 'high', 'low', 'close', 'volume']\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "  symbol        date      open      high       low     close    volume\n",
      "0    AAL  2014-01-02   25.0700   25.8200   25.0600   25.3600   8998943\n",
      "1   AAPL  2014-01-02   79.3828   79.5756   78.8601   79.0185  58791957\n",
      "2    AAP  2014-01-02  110.3600  111.8800  109.2900  109.7400    542711\n",
      "3   ABBV  2014-01-02   52.1200   52.3300   51.5200   51.9800   4569061\n",
      "4    ABC  2014-01-02   70.1100   70.2300   69.4800   69.8900   1148391\n",
      "\n",
      "=== Data Types ===\n",
      "symbol     object\n",
      "date       object\n",
      "open      float64\n",
      "high      float64\n",
      "low       float64\n",
      "close     float64\n",
      "volume      int64\n",
      "dtype: object\n",
      "\n",
      "=== DataFrame Information ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 497472 entries, 0 to 497471\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   symbol  497472 non-null  object \n",
      " 1   date    497472 non-null  object \n",
      " 2   open    497461 non-null  float64\n",
      " 3   high    497464 non-null  float64\n",
      " 4   low     497464 non-null  float64\n",
      " 5   close   497472 non-null  float64\n",
      " 6   volume  497472 non-null  int64  \n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 26.6+ MB\n",
      "None\n",
      "\n",
      "=== Descriptive Statistics ===\n",
      "                open           high            low          close  \\\n",
      "count  497461.000000  497464.000000  497464.000000  497472.000000   \n",
      "mean       86.352275      87.132562      85.552467      86.369082   \n",
      "std       101.471228     102.312062     100.570957     101.472407   \n",
      "min         1.620000       1.690000       1.500000       1.590000   \n",
      "25%        41.690000      42.090000      41.280000      41.703750   \n",
      "50%        64.970000      65.560000      64.353700      64.980000   \n",
      "75%        98.410000      99.230000      97.580000      98.420000   \n",
      "max      2044.000000    2067.990000    2035.110000    2049.000000   \n",
      "\n",
      "             volume  \n",
      "count  4.974720e+05  \n",
      "mean   4.253611e+06  \n",
      "std    8.232139e+06  \n",
      "min    0.000000e+00  \n",
      "25%    1.080166e+06  \n",
      "50%    2.084896e+06  \n",
      "75%    4.271928e+06  \n",
      "max    6.182376e+08  \n",
      "\n",
      "=== Missing Values ===\n",
      "symbol     0\n",
      "date       0\n",
      "open      11\n",
      "high       8\n",
      "low        8\n",
      "close      0\n",
      "volume     0\n",
      "dtype: int64\n",
      "\n",
      "=== Duplicate Rows ===\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "=== Stock Symbol Distribution ===\n",
      "symbol\n",
      "YUM     1007\n",
      "XYL     1007\n",
      "XRX     1007\n",
      "XRAY    1007\n",
      "XOM     1007\n",
      "XL      1007\n",
      "XLNX    1007\n",
      "XEL     1007\n",
      "XEC     1007\n",
      "WY      1007\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Feature Engineering ===\n",
      "Creating price change percentage feature...\n",
      "Creating high-low range percentage feature...\n",
      "Creating relative volume feature...\n",
      "Creating moving average features...\n",
      "Creating volatility features...\n",
      "Creating normalized features...\n",
      "Dropping 30398 rows with missing values after feature engineering...\n",
      "Original feature count: 7\n",
      "Engineered feature count: 28\n",
      "New features created: {'volatility_5d', 'norm_price_change_pct', 'volatility_10d', 'norm_open', 'norm_volatility_10d', 'norm_hl_range_pct', 'norm_high', 'norm_close', 'norm_ma5_volume', 'ma5_close', 'norm_ma5_close', 'rel_volume', 'norm_low', 'ma5_volume', 'norm_volume', 'norm_ma10_close', 'norm_rel_volume', 'hl_range_pct', 'price_change_pct', 'ma10_close', 'norm_volatility_5d'}\n",
      "\n",
      "=== Data Preprocessing ===\n",
      "Creating binary target variable: price_increased\n",
      "\n",
      "Class distribution:\n",
      "price_increased\n",
      "1    253810\n",
      "0    239110\n",
      "Name: count, dtype: int64\n",
      "Class distribution (%):\n",
      "price_increased\n",
      "1    51.491114\n",
      "0    48.508886\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryant\\AppData\\Local\\Temp\\ipykernel_5220\\1618005529.py:22: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.countplot(x='price_increased', data=df_processed, palette=['salmon', 'lightgreen'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape after initial selection: (492920, 22)\n",
      "Training set shape: (369690, 22), Test set shape: (123230, 22)\n",
      "\n",
      "=== Feature Selection ===\n",
      "Selected 10 features: ['volume', 'price_change_pct', 'hl_range_pct', 'rel_volume', 'ma5_volume', 'norm_open', 'norm_volume', 'norm_price_change_pct', 'norm_rel_volume', 'norm_ma5_volume']\n",
      "\n",
      "=== Training SVM Models ===\n",
      "\n",
      "Training SVM (Linear Kernel)...\n",
      "Performance of SVM (Linear Kernel):\n",
      "  Accuracy: 0.9990\n",
      "  Precision: 0.9998\n",
      "  Recall: 0.9982\n",
      "  F1 Score: 0.9990\n",
      "  AUC: 1.0000\n",
      "\n",
      "Training SVM (RBF Kernel)...\n",
      "Performance of SVM (RBF Kernel):\n",
      "  Accuracy: 0.9990\n",
      "  Precision: 0.9994\n",
      "  Recall: 0.9987\n",
      "  F1 Score: 0.9991\n",
      "  AUC: 1.0000\n",
      "\n",
      "=== Model Comparison ===\n",
      "           SVM (Linear Kernel)  SVM (RBF Kernel)\n",
      "Accuracy              0.998978          0.999042\n",
      "Precision             0.999842          0.999448\n",
      "Recall                0.998172          0.998692\n",
      "F1 Score              0.999006          0.999070\n",
      "AUC                   0.999998          0.999994\n",
      "\n",
      "Best model based on accuracy: SVM (RBF Kernel)\n",
      "Accuracy: 0.9990\n",
      "\n",
      "=== Optimizing SVM Hyperparameters for rbf kernel ===\n",
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the stock price SVM workflow\"\"\"\n",
    "    print(\"=== SVM Classification for Stock Price Direction Prediction ===\")\n",
    "    \n",
    "    # 1. Load data\n",
    "    df = load_data(\"Data set/Stock Prices Data Set.csv\")\n",
    "    if df is None:\n",
    "        print(\"Error loading data. Exiting...\")\n",
    "        return\n",
    "    \n",
    "    # 2. Explore data\n",
    "    explore_data(df\n",
    "                 )\n",
    "    \n",
    "    # 3. Engineer features\n",
    "    df_eng = engineer_features(df)\n",
    "    if df_eng is None:\n",
    "        print(\"Error engineering features. Exiting...\")\n",
    "        return\n",
    "    \n",
    "    # 4. Preprocess data\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(df_eng)\n",
    "    if X_train is None:\n",
    "        print(\"Error preprocessing data. Exiting...\")\n",
    "        return\n",
    "    \n",
    "    # 5. Select important features\n",
    "    X_train_selected, X_test_selected, selected_features = select_features(\n",
    "        X_train, X_test, y_train, k=None\n",
    "    )\n",
    "    if X_train_selected is None:\n",
    "        print(\"Error selecting features. Exiting...\")\n",
    "        return\n",
    "    \n",
    "    # 6. Train different SVM models\n",
    "    model_results = train_svm_models(X_train_selected, y_train, X_test_selected, y_test)\n",
    "    \n",
    "    # 7. Compare all models\n",
    "    best_model_name, best_model_results = compare_models(model_results)\n",
    "    \n",
    "    # 8. Optimize hyperparameters for the best kernel type\n",
    "    best_kernel = best_model_name.split('(')[1].split(' ')[0].lower()\n",
    "    optimized_model = optimize_svm_hyperparameters(X_train_selected, y_train, kernel=best_kernel)\n",
    "    \n",
    "    # 9. Perform cross-validation on the optimized model\n",
    "    cv_scores = perform_cross_validation(X_train_selected, y_train, optimized_model.named_steps['svm'])\n",
    "    \n",
    "    # 10. Evaluate the optimized model\n",
    "    # Predict with optimized model\n",
    "    X_test_scaled = optimized_model.named_steps['scaler'].transform(X_test_selected)\n",
    "    y_pred = optimized_model.named_steps['svm'].predict(X_test_scaled)\n",
    "    y_prob = optimized_model.named_steps['svm'].predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Create results dictionary for the optimized model\n",
    "    optimized_results = {\n",
    "        'model': optimized_model.named_steps['svm'],\n",
    "        'scaler': optimized_model.named_steps['scaler'],\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_prob)\n",
    "    }\n",
    "    \n",
    "    optimized_metrics = evaluate_model(\n",
    "        optimized_results, X_test_selected, y_test, \n",
    "        model_name=f\"Optimized {best_kernel.upper()} SVM\"\n",
    "    )\n",
    "    \n",
    "    # 11. Visualize decision boundary for the best model\n",
    "    visualize_decision_boundary(\n",
    "        optimized_results, X_test_selected, y_test, \n",
    "        selected_features, f\"Optimized {best_kernel.upper()} SVM\"\n",
    "    )\n",
    "    \n",
    "    # 12. Save the optimized model\n",
    "    save_model(\n",
    "        optimized_model.named_steps['svm'], \n",
    "        optimized_model.named_steps['scaler'], \n",
    "        selected_features, \n",
    "        filename=f'optimized_{best_kernel}_svm_stock_model.pkl'\n",
    "    )\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n=== Summary ===\")\n",
    "    print(f\"1. Dataset shape: {df.shape}\")\n",
    "    print(f\"2. Number of engineered features: {df_eng.shape[1] - df.shape[1]}\")\n",
    "    print(f\"3. Number of selected features: {len(selected_features)}\")\n",
    "    print(f\"4. Best basic model: {best_model_name}\")\n",
    "    print(f\"5. Best model accuracy: {best_model_results['accuracy']:.4f}\")\n",
    "    print(f\"6. Optimized model accuracy: {optimized_metrics['accuracy']:.4f}\")\n",
    "    print(f\"7. Cross-validation accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
    "    \n",
    "    print(\"\\nConclusion:\")\n",
    "    if optimized_metrics['accuracy'] >= best_model_results['accuracy']:\n",
    "        improvement = optimized_metrics['accuracy'] - best_model_results['accuracy']\n",
    "        print(f\"Hyperparameter optimization improved model accuracy by {improvement:.4f}!\")\n",
    "    else:\n",
    "        diff = best_model_results['accuracy'] - optimized_metrics['accuracy']\n",
    "        print(f\"The basic model outperformed the optimized model by {diff:.4f}.\")\n",
    "        print(\"This suggests possible overfitting during optimization or that the basic model was already well-tuned.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355e3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
